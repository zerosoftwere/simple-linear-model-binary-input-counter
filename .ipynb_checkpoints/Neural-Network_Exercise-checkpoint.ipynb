{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Gradient Descent Algorithm\n",
    "\n",
    "In this lab, we'll implement the basic functions of the Gradient Descent algorithm to find the number of ones in the input dataset. First, we'll start by importing the math library to help make computation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2  x3  x4  y\n",
       "0    0   0   0   0  0\n",
       "1    0   0   0   1  1\n",
       "2    0   0   1   0  1\n",
       "3    0   0   1   1  2\n",
       "4    0   1   0   0  1\n",
       "5    0   1   0   1  2\n",
       "6    0   1   1   0  2\n",
       "7    0   1   1   1  3\n",
       "8    1   0   0   0  1\n",
       "9    1   0   0   1  2\n",
       "10   1   0   1   0  2\n",
       "11   1   0   1   1  3\n",
       "12   1   1   0   0  2\n",
       "13   1   1   0   1  3\n",
       "14   1   1   1   0  3\n",
       "15   1   1   1   1  4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Data Set from Labels\n",
    "\n",
    "This procedure would extract the input data (features) and the labels (targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array(data[['x1', 'x2', 'x3', 'x4']])\n",
    "ys = np.array(data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Set in to Training Data and Test Data\n",
    "Here we randomly sample the 70% of the data to be used for the training and the other 30% would be used to verify our training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (11, 4)\n",
      "Test data shape:  (5, 4)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(xs.shape[0])\n",
    "\n",
    "training_indices = np.random.choice(indices, size=int(np.floor(0.7 * len(indices))), replace=False);\n",
    "test_indices = np.array([x for x in indices if x not in training_indices])\n",
    "\n",
    "training_data = xs[training_indices];\n",
    "training_labels = ys[training_indices];\n",
    "\n",
    "test_data = xs[test_indices];\n",
    "test_labels = ys[test_indices];\n",
    "\n",
    "print('Train data shape:', training_data.shape)\n",
    "print('Test data shape: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the basic functions\n",
    "Here is your turn to shine. Implement the following formulas, as explained in the text.\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = (w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$E = (\\hat{y} - y)^2$$\n",
    "\n",
    "- Gradient function\n",
    "\n",
    "$$E^\\prime = 2(\\hat{y} - y)$$\n",
    "\n",
    "- Mean squared Error function\n",
    "\n",
    "$$MSE = \\frac{1}{2m}\\sum{(\\hat{y} - y)^2}$$\n",
    "\n",
    "\n",
    "- Deferential of Mean squared Error function\n",
    "\n",
    "$$MSE^\\prime = \\frac{1}{m}\\sum{(\\hat{y} - y)x_i}$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i - \\frac{\\alpha}{m}\\sum{(\\hat{y} - y)}x_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output (prediction) formula\n",
    "def output_formula(features, weights):\n",
    "    return np.dot(features, weights)\n",
    "\n",
    "# Error formula\n",
    "def error_formula(y_hat, y):\n",
    "    return (y_hat - y) ** 2\n",
    "\n",
    "def error_formula_prime(y_hat, y):\n",
    "    return y_hat - y\n",
    "\n",
    "def MSE(y_hats, ys):\n",
    "    return np.mean((y_hats - ys) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function\n",
    "This function will help us iterate the gradient descent algorithm through all the data, for a number of epochs.\n",
    "\n",
    "- Prediction fuction \n",
    "\n",
    "$$\\hat{y} = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4$$\n",
    "\n",
    "- Compute the gradinet \n",
    "\n",
    "$$\\delta = (\\hat{y} - y)$$\n",
    "\n",
    "- Update the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i - \\alpha * \\delta * x_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(xs, ys, weights, epochs, learnrate):\n",
    "    \n",
    "    errors = []\n",
    "    n_records, n_features = xs.shape\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for x, y in zip(xs, ys):\n",
    "            # Feed Forward function\n",
    "            y_hat = output_formula(x, weights)\n",
    "            # Compute gradient\n",
    "            d_error = error_formula_prime(y_hat, y)\n",
    "            # Update weights\n",
    "            weights = weights - learnrate * d_error * x\n",
    "        \n",
    "        \n",
    "        # Printing out the loss error on the training set\n",
    "        y_hats = output_formula(xs, weights)\n",
    "        loss = MSE(y_hats, ys)\n",
    "        errors.append(loss)\n",
    "        \n",
    "        if e % (epochs / 10) == 0:\n",
    "            print(\"\\n========== Epoch\", e,\"==========\")\n",
    "            print(\"Train loss: \", loss)\n",
    "    \n",
    "    # Plotting the error\n",
    "    plt.plot(errors)\n",
    "    plt.show()\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Random Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights [-0.98038552  1.98519745 -0.40150305  1.63395502]\n"
     ]
    }
   ],
   "source": [
    "# Intialize weights\n",
    "weights = np.random.normal(size=4)\n",
    "print('Weights', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to train the algorithm!\n",
    "The training algorithim uses a learning rate ($\\alpha$) of 0.1 and a total of 100 iterations (epochs) to train the model over the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Epoch 0 ==========\n",
      "Train loss:  0.413827295966\n",
      "\n",
      "========== Epoch 5 ==========\n",
      "Train loss:  0.000180905734768\n",
      "\n",
      "========== Epoch 10 ==========\n",
      "Train loss:  8.45985014432e-08\n",
      "\n",
      "========== Epoch 15 ==========\n",
      "Train loss:  3.99598924278e-11\n",
      "\n",
      "========== Epoch 20 ==========\n",
      "Train loss:  1.88877670468e-14\n",
      "\n",
      "========== Epoch 25 ==========\n",
      "Train loss:  8.92773955375e-18\n",
      "\n",
      "========== Epoch 30 ==========\n",
      "Train loss:  4.21989909359e-21\n",
      "\n",
      "========== Epoch 35 ==========\n",
      "Train loss:  1.99491577788e-24\n",
      "\n",
      "========== Epoch 40 ==========\n",
      "Train loss:  9.44333736013e-28\n",
      "\n",
      "========== Epoch 45 ==========\n",
      "Train loss:  4.01153698962e-31\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reintialize weights\n",
    "weights = np.random.normal(size=4)\n",
    "# Perform training\n",
    "weights = train(training_data, training_labels, weights, 50, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print('Weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 2 4] [ 0.  1.  2.  2.  4.]\n"
     ]
    }
   ],
   "source": [
    "pred = output_formula(test_data, weights)\n",
    "print(test_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray: 100.000000%\n"
     ]
    }
   ],
   "source": [
    "ps = pred.sum()\n",
    "ts = test_labels.sum()\n",
    "\n",
    "accuracy = (ts / ps if ps > ts else ps / ts) * 100.0\n",
    "print('Accuray: %f%%' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
