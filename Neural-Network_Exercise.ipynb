{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Gradient Descent Algorithm\n",
    "\n",
    "In this lab, we'll implement the basic functions of the Gradient Descent algorithm to find the number of ones in the input dataset. First, we'll start by importing the math library to help make computation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2  x3  x4  y\n",
       "0    0   0   0   0  0\n",
       "1    0   0   0   1  1\n",
       "2    0   0   1   0  1\n",
       "3    0   0   1   1  2\n",
       "4    0   1   0   0  1\n",
       "5    0   1   0   1  2\n",
       "6    0   1   1   0  2\n",
       "7    0   1   1   1  3\n",
       "8    1   0   0   0  1\n",
       "9    1   0   0   1  2\n",
       "10   1   0   1   0  2\n",
       "11   1   0   1   1  3\n",
       "12   1   1   0   0  2\n",
       "13   1   1   0   1  3\n",
       "14   1   1   1   0  3\n",
       "15   1   1   1   1  4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Data Set from Labels\n",
    "\n",
    "This procedure would extract the input data (features) and the labels (targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array(data[['x1', 'x2', 'x3', 'x4']])\n",
    "ys = np.array(data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Set in to Training Data and Test Data\n",
    "Here we randomly sample the 70% of the data to be used for the training and the other 30% would be used to verify our training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (11, 4)\n",
      "Test data shape:  (5, 4)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(xs.shape[0])\n",
    "\n",
    "training_indices = np.random.choice(indices, size=int(np.floor(0.7 * len(indices))), replace=False);\n",
    "test_indices = np.array([x for x in indices if x not in training_indices])\n",
    "\n",
    "training_data = xs[training_indices];\n",
    "training_labels = ys[training_indices];\n",
    "\n",
    "test_data = xs[test_indices];\n",
    "test_labels = ys[test_indices];\n",
    "\n",
    "print('Train data shape:', training_data.shape)\n",
    "print('Test data shape: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the basic functions\n",
    "Here is your turn to shine. Implement the following formulas, as explained in the text.\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = (w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$E = (\\hat{y} - y)^2$$\n",
    "\n",
    "- Gradient function\n",
    "\n",
    "$$E^\\prime = 2(\\hat{y} - y)$$\n",
    "\n",
    "- Mean squared Error function\n",
    "\n",
    "$$MSE = \\frac{1}{2m}\\sum{(\\hat{y} - y)^2}$$\n",
    "\n",
    "\n",
    "- Deferential of Mean squared Error function\n",
    "\n",
    "$$MSE^\\prime = \\frac{1}{m}\\sum{(\\hat{y} - y)x_i}$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i - \\frac{\\alpha}{m}\\sum{(\\hat{y} - y)}x_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output (prediction) formula\n",
    "def output_formula(features, weights):\n",
    "    return np.dot(features, weights)\n",
    "\n",
    "# Error formula\n",
    "def error_formula(y_hat, y):\n",
    "    return (y_hat - y) ** 2\n",
    "\n",
    "def error_formula_prime(y_hat, y):\n",
    "    return y_hat - y\n",
    "\n",
    "def MSE(y_hats, ys):\n",
    "    return np.mean((y_hats - ys) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function\n",
    "This function will help us iterate the gradient descent algorithm through all the data, for a number of epochs.\n",
    "\n",
    "- Prediction fuction \n",
    "\n",
    "$$\\hat{y} = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4$$\n",
    "\n",
    "- Compute the gradinet \n",
    "\n",
    "$$\\delta = (\\hat{y} - y)$$\n",
    "\n",
    "- Update the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i - \\alpha * \\delta * x_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(xs, ys, weights, epochs, learnrate):\n",
    "    \n",
    "    errors = []\n",
    "    n_records, n_features = xs.shape\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for x, y in zip(xs, ys):\n",
    "            # Feed Forward function\n",
    "            y_hat = output_formula(x, weights)\n",
    "            # Compute gradient\n",
    "            d_error = error_formula_prime(y_hat, y)\n",
    "            # Update weights\n",
    "            weights = weights - learnrate * d_error * x\n",
    "        \n",
    "        \n",
    "        # Printing out the loss error on the training set\n",
    "        y_hats = output_formula(xs, weights)\n",
    "        loss = MSE(y_hats, ys)\n",
    "        errors.append(loss)\n",
    "        \n",
    "        if e % (epochs / 10) == 0:\n",
    "            print(\"\\n========== Epoch\", e,\"==========\")\n",
    "            print(\"Train loss: \", loss)\n",
    "    \n",
    "    # Plotting the error\n",
    "    plt.plot(errors)\n",
    "    plt.show()\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Random Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights [ 0.81166833  1.42195884 -0.03284291 -0.44724935]\n"
     ]
    }
   ],
   "source": [
    "# Intialize weights\n",
    "weights = np.random.normal(size=4)\n",
    "print('Weights', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to train the algorithm!\n",
    "The training algorithim uses a learning rate ($\\alpha$) of 0.4 and a total of 50 iterations (epochs) to train the model over the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Epoch 0 ==========\n",
      "Train loss:  0.0199206598404\n",
      "\n",
      "========== Epoch 5 ==========\n",
      "Train loss:  5.2706978862e-09\n",
      "\n",
      "========== Epoch 10 ==========\n",
      "Train loss:  4.12953396481e-15\n",
      "\n",
      "========== Epoch 15 ==========\n",
      "Train loss:  6.85031606136e-22\n",
      "\n",
      "========== Epoch 20 ==========\n",
      "Train loss:  6.73924767763e-28\n",
      "\n",
      "========== Epoch 25 ==========\n",
      "Train loss:  4.48216423421e-33\n",
      "\n",
      "========== Epoch 30 ==========\n",
      "Train loss:  4.48216423421e-33\n",
      "\n",
      "========== Epoch 35 ==========\n",
      "Train loss:  4.48216423421e-33\n",
      "\n",
      "========== Epoch 40 ==========\n",
      "Train loss:  4.48216423421e-33\n",
      "\n",
      "========== Epoch 45 ==========\n",
      "Train loss:  4.48216423421e-33\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHcZJREFUeJzt3X+QXWWd5/H3p+/tvtdfBIgNFZJo\nZ4aeXcOMxrUn6+rslkMWDK4SLGFtyh9xK1OxpkiptUPthtmCnaWkSqacwbJgrIoma6RGE8zI2rNm\nNoOQqR123JgOZISAWdoYTJsUaUhEQDuhk+/+cZ+bnNw+996TpDs99P28qrr6nOc85+nzFKE//Zzn\n3PMoIjAzM2uma6YvwMzM/mlzUJiZWUsOCjMza8lBYWZmLTkozMysJQeFmZm15KAwM7OWHBRmZtaS\ng8LMzFoqz/QFTIU3v/nN0dfXN9OXYWb2mrJr167nI6K3Xb1ZERR9fX0MDw/P9GWYmb2mSHq2SD3f\nejIzs5YcFGZm1pKDwszMWnJQmJlZS4WCQtJySXsljUham3O8ImlzOr5DUl8qv0bSLklPpO9XZ855\nVyofkfRlSUrll0p6SNIz6fslU9NVMzM7F22DQlIJuA+4DlgM3CxpcUO1VcDRiLgSuAe4O5U/D3wo\nIn4HWAncnznnK8BqoD99LU/la4GHI6IfeDjtm5nZDCkyolgKjETEvog4DmwCVjTUWQFsTNtbgGWS\nFBGPR8TBVL4HqKbRxzzgooj4QdSW2PsGcENOWxsz5WZmNgOKBMV84EBmfzSV5daJiAngRWBuQ52P\nAI9HxLFUf7RJm5dHxKHU1iHgsryLkrRa0rCk4bGxsQLdmGzn/iN8cdteJk6cPKfzzcw6QZGgUE5Z\n40LbLetIuora7ahPn0WbLUXEuogYiIiB3t62HyzMtftnv+De7SOMTzgozMyaKRIUo8DCzP4C4GCz\nOpLKwBzgSNpfADwIfDIifpKpv6BJm8+lW1Ok74eLduZsVbpr3R9/9cR0/Qgzs9e8IkGxE+iXtEhS\nDzAIDDXUGaI2WQ1wI/BIRISki4HvAbdFxP+pV063lF6S9O70tNMnge/mtLUyUz7lquUSAMc8ojAz\na6ptUKQ5hzXANuBp4IGI2CPpTknXp2rrgbmSRoD/yOknldYAVwK3S9qdvupzDn8IfA0YAX4C/E0q\n/wJwjaRngGvS/rTwiMLMrL1CLwWMiK3A1oayOzLb48BNOed9Hvh8kzaHgd/OKX8BWFbkus5XJY0o\nHBRmZs119Cezq2lE4VtPZmbNdXhQeERhZtaOgwI49qpHFGZmzXR0UFTKnsw2M2uno4Pi1IjCcxRm\nZk11eFB4RGFm1k5HB4UfjzUza6+jg8KPx5qZtdfZQXFqROGgMDNrpqODoqtL9JS6GJ/wrSczs2Y6\nOiig9ois5yjMzJpzUHSXPEdhZtZCxwdFtdsjCjOzVjo+KCrlLr/Cw8yshY4Pimp3iWOezDYza8pB\n0V3y47FmZi0UCgpJyyXtlTQiaW3O8Yqkzen4Dkl9qXyupO2SXpZ0b6b+mzIr3u2W9LykL6Vjn5I0\nljn2B1PT1Xx+6snMrLW2K9xJKgH3UVuWdBTYKWkoIp7KVFsFHI2IKyUNAncDHwXGgduprWR3ajW7\niHgJWJL5GbuA72Ta2xwRa865V2eh2l3ipfGJC/GjzMxek4qMKJYCIxGxLyKOA5uAFQ11VgAb0/YW\nYJkkRcQrEfEotcDIJakfuAz4+7O++ingp57MzForEhTzgQOZ/dFUllsnIiaAF4G5Ba/hZmojiMiU\nfUTSjyRtkbQw7yRJqyUNSxoeGxsr+KMmq5ZL/mS2mVkLRYJCOWVxDnWaGQS+ldn/a6AvIt4OfJ/T\nI5UzG49YFxEDETHQ29tb8EdNVunu8mS2mVkLRYJiFMj+Vb8AONisjqQyMAc40q5hSe8AyhGxq14W\nES9ExLG0+1XgXQWu8ZxVyiWO+daTmVlTRYJiJ9AvaZGkHmojgKGGOkPAyrR9I/BIw62kZm7mzNEE\nkuZldq8Hni7QzjmrdpcY9ys8zMyaavvUU0RMSFoDbANKwIaI2CPpTmA4IoaA9cD9kkaojSQG6+dL\n2g9cBPRIugG4NvPE1L8HPtDwIz8j6XpgIrX1qfPoX1uVchfHJ05y8mTQ1ZV3B83MrLO1DQqAiNgK\nbG0ouyOzPQ7c1OTcvhbt/kZO2W3AbUWuayrU180+fuIk1a7ShfqxZmavGf5kttfNNjNryUHR7VXu\nzMxa6figqJQ9ojAza6Xjg6I+ovDiRWZm+RwUnqMwM2up44OiUq7PUTgozMzydHxQ1EcUvvVkZpav\n44PCIwozs9Y6PihOzVF4RGFmlqvjg8IjCjOz1jo+KPx4rJlZaw6K+mS2RxRmZrk6Pih868nMrLWO\nD4rukuiSbz2ZmTXT8UEhqbZ4kUcUZma5CgWFpOWS9koakbQ253hF0uZ0fIekvlQ+V9J2SS9Lurfh\nnL9Lbe5OX5e1ams6VcpeN9vMrJm2QSGpBNwHXAcsBm6WtLih2irgaERcCdwD3J3Kx4HbgVubNP+x\niFiSvg63aWvaeERhZtZckRHFUmAkIvZFxHFgE7Cioc4KYGPa3gIsk6SIeCUiHqUWGEXltnUW55+1\nanfJcxRmZk0UCYr5wIHM/mgqy60TERPAi8DcAm3/93Tb6fZMGJxrW+esduvJIwozszxFgiLvr/k4\nhzqNPhYRvwP86/T1ibNpS9JqScOShsfGxtr8qNYq3SW/wsPMrIkiQTEKLMzsLwAONqsjqQzMAY60\najQifp6+vwR8k9otrsJtRcS6iBiIiIHe3t4C3WiuWu7yB+7MzJooEhQ7gX5JiyT1AIPAUEOdIWBl\n2r4ReCQimo4oJJUlvTltdwMfBJ48l7amQtUjCjOzpsrtKkTEhKQ1wDagBGyIiD2S7gSGI2IIWA/c\nL2mE2l//g/XzJe0HLgJ6JN0AXAs8C2xLIVECvg98NZ3StK3pUvGIwsysqbZBARARW4GtDWV3ZLbH\ngZuanNvXpNl3NanftK3p4sdjzcya6/hPZkPtxYB+PNbMLJ+DgtqLAT2iMDPL56CgNqLwKzzMzPI5\nKKh/MvsE0/xwlZnZa5KDglpQnAx49YSDwsyskYOC2uOxAOMTnqcwM2vkoKD2Cg/wKndmZnkcFNRe\n4QFwzBPaZmaTOCg4PaI45ltPZmaTOCg4PaLwI7JmZpM5KKg99QQeUZiZ5XFQkHnqySMKM7NJHBSc\nHlH4qSczs8kcFGRvPXlEYWbWyEFB7V1P4BGFmVkeBwW1t8eC5yjMzPIUCgpJyyXtlTQiaW3O8Yqk\nzen4Dkl9qXyupO2SXpZ0b6b+6yV9T9KPJe2R9IXMsU9JGpO0O339wfl3szWPKMzMmmsbFJJKwH3A\ndcBi4GZJixuqrQKORsSVwD3A3al8HLgduDWn6S9GxD8H3gm8V9J1mWObI2JJ+vraWfXoHHiOwsys\nuSIjiqXASETsi4jjwCZgRUOdFcDGtL0FWCZJEfFKRDxKLTBOiYhfRcT2tH0ceAxYcB79OC89JY8o\nzMyaKRIU84EDmf3RVJZbJyImgBeBuUUuQNLFwIeAhzPFH5H0I0lbJC0s0s756OoSPeUuvz3WzCxH\nkaBQTlnjwg1F6kxuWCoD3wK+HBH7UvFfA30R8Xbg+5weqTSeu1rSsKThsbGxdj+qrWq5yy8FNDPL\nUSQoRoHsX/ULgIPN6qRf/nOAIwXaXgc8ExFfqhdExAsRcSztfhV4V96JEbEuIgYiYqC3t7fAj2qt\nvsqdmZmdqUhQ7AT6JS2S1AMMAkMNdYaAlWn7RuCRaLOuqKTPUwuUzzWUz8vsXg88XeAaz1vF62ab\nmeUqt6sQEROS1gDbgBKwISL2SLoTGI6IIWA9cL+kEWojicH6+ZL2AxcBPZJuAK4Ffgn8F+DHwGOS\nAO5NTzh9RtL1wERq61NT1NeWquWSJ7PNzHK0DQqAiNgKbG0ouyOzPQ7c1OTcvibN5s1rEBG3AbcV\nua6pVLv15BGFmVkjfzI7qZS7PKIwM8vhoEiq3b71ZGaWx0GRVLu7fOvJzCyHgyKpeDLbzCyXgyLx\n47FmZvkcFIk/cGdmls9BkVTLJb/Cw8wsh4MiqXT7pYBmZnkcFEm1XOLVE8GJk23fZWhm1lEcFEl9\nlTvPU5iZnclBkVTK9cWLPE9hZpbloEjqy6H6sxRmZmdyUCQOCjOzfA6KpH7rya/xMDM7k4Mi8YjC\nzCyfgyKpdHsy28wsT6GgkLRc0l5JI5LW5hyvSNqcju+Q1JfK50raLullSfc2nPMuSU+kc76stMyd\npEslPSTpmfT9kvPvZnv1EYUfjzUzO1PboJBUAu4DrgMWAzdLWtxQbRVwNCKuBO4B7k7l48DtwK05\nTX8FWA30p6/lqXwt8HBE9AMPp/1p58djzczyFRlRLAVGImJfRBwHNgErGuqsADam7S3AMkmKiFci\n4lFqgXGKpHnARRHxg4gI4BvADTltbcyUTyuPKMzM8hUJivnAgcz+aCrLrRMRE8CLwNw2bY42afPy\niDiU2joEXFbgGs+bJ7PNzPIVCQrllDW+EKlInfOpP7kBabWkYUnDY2NjZ3NqLj8ea2aWr0hQjAIL\nM/sLgIPN6kgqA3OAI23aXNCkzefSran6LarDeQ1ExLqIGIiIgd7e3gLdaM0jCjOzfEWCYifQL2mR\npB5gEBhqqDMErEzbNwKPpLmHXOmW0kuS3p2edvok8N2ctlZmyqdV1ZPZZma5yu0qRMSEpDXANqAE\nbIiIPZLuBIYjYghYD9wvaYTaSGKwfr6k/cBFQI+kG4BrI+Ip4A+BrwOvA/4mfQF8AXhA0irgZ8BN\nU9HRdsqlLspd8mS2mVmDtkEBEBFbga0NZXdktsdp8gs9IvqalA8Dv51T/gKwrMh1TbVK2etmm5k1\n8iezM6rdJc9RmJk1cFBk1ILCIwozsywHRUal3OU5CjOzBg6KjIpHFGZmkzgoMqrdHlGYmTVyUGRU\nyl0c84jCzOwMDoqManeJcY8ozMzO4KDIqJb9eKyZWSMHRUZtjsK3nszMshwUGRWPKMzMJnFQZFS7\n/QoPM7NGDooMv8LDzGwyB0VG7ZPZJ2nxhnQzs47joMionFo327efzMzqHBQZ9VXu/KE7M7PTHBQZ\n1e76utmepzAzqysUFJKWS9oraUTS2pzjFUmb0/Edkvoyx25L5XslvT+V/TNJuzNfv5T0uXTsTyT9\nPHPsA1PT1fYq5fq62R5RmJnVtV3hTlIJuA+4BhgFdkoaSsuZ1q0CjkbElZIGgbuBj0paTG1Z1KuA\nK4DvS/qtiNgLLMm0/3PgwUx790TEF8+/e2enPqLwazzMzE4rMqJYCoxExL6IOA5sAlY01FkBbEzb\nW4BlkpTKN0XEsYj4KTCS2staBvwkIp49105MleqpEYWDwsysrkhQzAcOZPZHU1lunYiYAF4E5hY8\ndxD4VkPZGkk/krRB0iV5FyVptaRhScNjY2MFutFe5dQchW89mZnVFQkK5ZQ1ftCgWZ2W50rqAa4H\nvp05/hXgN6ndmjoE/FneRUXEuogYiIiB3t7e5ld/FupPPXlEYWZ2WpGgGAUWZvYXAAeb1ZFUBuYA\nRwqcex3wWEQ8Vy+IiOci4kREnAS+yuRbVdOm6slsM7NJigTFTqBf0qI0AhgEhhrqDAEr0/aNwCNR\n+3jzEDCYnopaBPQDP8ycdzMNt50kzcvsfhh4smhnzlfFj8eamU3S9qmniJiQtAbYBpSADRGxR9Kd\nwHBEDAHrgfsljVAbSQymc/dIegB4CpgAbomIEwCSXk/tSapPN/zIP5W0hNotqv05x6eNRxRmZpO1\nDQqAiNgKbG0ouyOzPQ7c1OTcu4C7csp/RW3Cu7H8E0WuaTqcejzWcxRmZqf4k9kZFU9mm5lN4qDI\nqJT9eKyZWSMHRUal3IUExzyiMDM7xUGRIYlKuYtxjyjMzE5xUDSolEseUZiZZTgoGnjdbDOzMzko\nGlS7S357rJlZhoOiQaXc5cdjzcwyHBQNqt0lPx5rZpbhoGhQLZc8ojAzy3BQNKh4MtvM7AwOigaV\nsm89mZllOSgaVLu7/DkKM7MMB0WDarfnKMzMshwUDfwKDzOzMzkoGlS7/QoPM7OsQkEhabmkvZJG\nJK3NOV6RtDkd3yGpL3PstlS+V9L7M+X7JT0habek4Uz5pZIekvRM+n7J+XXx7FS7PaIwM8tqGxSS\nSsB9wHXAYuBmSYsbqq0CjkbElcA9wN3p3MXUlkW9ClgO/EVqr+73I2JJRAxkytYCD0dEP/Bw2r9g\nquUSJ04Gr55wWJiZQbERxVJgJCL2RcRxYBOwoqHOCmBj2t4CLJOkVL4pIo5FxE+BkdReK9m2NgI3\nFLjGKVPp9uJFZmZZRYJiPnAgsz+aynLrRMQE8CK19bBbnRvA30raJWl1ps7lEXEotXUIuCzvoiSt\nljQsaXhsbKxAN4qpejlUM7MzFAkK5ZRFwTqtzn1vRPwLare0bpH0bwpcy+lGItZFxEBEDPT29p7N\nqS1Vyw4KM7OsIkExCizM7C8ADjarI6kMzAGOtDo3IurfDwMPcvqW1HOS5qW25gGHi3fn/NVvPfk1\nHmZmNUWCYifQL2mRpB5qk9NDDXWGgJVp+0bgkYiIVD6YnopaBPQDP5T0BklvApD0BuBa4MmctlYC\n3z23rp2bShpRHPOaFGZmAJTbVYiICUlrgG1ACdgQEXsk3QkMR8QQsB64X9IItZHEYDp3j6QHgKeA\nCeCWiDgh6XLgwdp8N2XgmxHxv9KP/ALwgKRVwM+Am6awv21VPaIwMztD26AAiIitwNaGsjsy2+M0\n+YUeEXcBdzWU7QPe0aT+C8CyItc1HU6NKDxHYWYG+JPZk1T9eKyZ2RkcFA38eKyZ2ZkcFA1OBYUn\ns83MAAfFJJVyuvXkyWwzM8BBMYlvPZmZnclB0eDU47GezDYzAxwUk1T8Cg8zszM4KBqUukR3SX48\n1swscVDkqJa9braZWZ2DIkelu8uv8DAzSxwUOSrlkl8KaGaWOChyVLu7/DkKM7PEQZGj2u05CjOz\nOgdFjkq5y6/wMDNLHBQ5qt0l33oyM0sKBYWk5ZL2ShqRtDbneEXS5nR8h6S+zLHbUvleSe9PZQsl\nbZf0tKQ9kj6bqf8nkn4uaXf6+sD5d/PsVLtLHlGYmSVtFy6SVALuA66htgb2TklDEfFUptoq4GhE\nXClpELgb+KikxdRWu7sKuAL4vqTforba3R9FxGNpSdRdkh7KtHlPRHxxqjp5tiplPx5rZlZXZESx\nFBiJiH0RcRzYBKxoqLMC2Ji2twDLVFvndAWwKSKORcRPgRFgaUQciojHACLiJeBpYP75d2dqVLv9\neKyZWV2RoJgPHMjsjzL5l/qpOhExAbwIzC1ybrpN9U5gR6Z4jaQfSdog6ZIC1zilqv7AnZnZKUWC\nQjllUbBOy3MlvRH4K+BzEfHLVPwV4DeBJcAh4M9yL0paLWlY0vDY2FjrHpylil/hYWZ2SpGgGAUW\nZvYXAAeb1ZFUBuYAR1qdK6mbWkj8ZUR8p14hIp6LiBMRcRL4KrVbX5NExLqIGIiIgd7e3gLdKK7i\nD9yZmZ1SJCh2Av2SFknqoTY5PdRQZwhYmbZvBB6JiEjlg+mpqEVAP/DDNH+xHng6Iv4825CkeZnd\nDwNPnm2nzle1XOL4iZOcPNk4cDIz6zxtn3qKiAlJa4BtQAnYEBF7JN0JDEfEELVf+vdLGqE2khhM\n5+6R9ADwFLUnnW6JiBOSfg/4BPCEpN3pR/1xRGwF/lTSEmq3qPYDn57C/hZSX+Xu2MRJXtdTutA/\n3szsn5S2QQGQfoFvbSi7I7M9DtzU5Ny7gLsayh4lf/6CiPhEkWuaTvV1s8dfPeGgMLOO509m58iO\nKMzMOp2DIsepdbP95JOZmYMiz6l1s/2hOzMzB0We0yMK33oyM3NQ5KjPUbw8PjHDV2JmNvMcFDmu\nuuIiKuUuvvfEoZm+FDOzGeegyHHx63v48Dvn8+Djo/ziV8dn+nLMzGaUg6KJle/pY/zVkzwwfKB9\nZTOzWcxB0cTb5l3E0kWX8o0fPMsJv8rDzDqYg6KF//CePkaP/pqHn35upi/FzGzGOChauGbx5Vwx\np8rX/2H/TF+KmdmMcVC0UC518fF/9Vb+4Scv8P+ee2mmL8fMbEY4KNoY/N230FPuYqNHFWbWoRwU\nbVz6hh5uWHIF33ns57z4q1dn+nLMzC44B0UBK9/Tx69fPcG3d/lRWTPrPA6KAq66Yg5L+y5l4w/2\n+1FZM+s4hYJC0nJJeyWNSFqbc7wiaXM6vkNSX+bYbal8r6T3t2szLbm6Q9Izqc2e8+vi1Fj5nj4O\nHPk12398eKYvxczsgmobFJJKwH3AdcBi4GZJixuqrQKORsSVwD3A3encxdSWRb0KWA78haRSmzbv\nBu6JiH7gaGp7xl171eXM86OyZtaBiowolgIjEbEvIo4Dm4AVDXVWABvT9hZgmSSl8k0RcSwifgqM\npPZy20znXJ3aILV5w7l3b+p0l7r4+LvfyqMjz7Nl1yi7nj3C/udf4aXxV4nw7Sgzm72KrJk9H8jO\n4o4C/7JZnYiYkPQiMDeV/9+Gc+en7bw25wK/iIiJnPozbvB3F7L+0Z9y67f/8YzynnIXc9/QM2l9\n7eyi4LUMnCy/1MysmM8s6+dD77hiWn9GkaDI+13W+Cd0szrNyvNGMq3qT74oaTWwGuAtb3lLXpUp\nN/eNFbbf+j4OHPkVz798jBdePs6RV47z/CvHeP6l4xzLrIh3xkU3GXBEswNmZgXNeV33tP+MIkEx\nCizM7C8ADjapMyqpDMwBjrQ5N6/8eeBiSeU0qsj7WQBExDpgHcDAwMAF+40753XdzJk/50L9ODOz\nGVdkjmIn0J+eRuqhNjk91FBnCFiZtm8EHonajfshYDA9FbUI6Ad+2KzNdM721Aapze+ee/fMzOx8\ntR1RpDmHNcA2oARsiIg9ku4EhiNiCFgP3C9phNpIYjCdu0fSA8BTwARwS0ScAMhrM/3I/wxskvR5\n4PHUtpmZzRDNhid2BgYGYnh4eKYvw8zsNUXSrogYaFfPn8w2M7OWHBRmZtaSg8LMzFpyUJiZWUsO\nCjMza2lWPPUkaQx49hxPfzO1D/p1mk7tN3Ru393vzlKk32+NiN52Dc2KoDgfkoaLPB4223Rqv6Fz\n++5+d5ap7LdvPZmZWUsOCjMza8lBkV4s2IE6td/QuX13vzvLlPW74+cozMysNY8ozMyspY4OCknL\nJe2VNCJp7Uxfz3SRtEHSYUlPZsoulfSQpGfS90tm8hqng6SFkrZLelrSHkmfTeWzuu+SqpJ+KOkf\nU7//WypfJGlH6vfm9Ir/WUdSSdLjkv5n2p/1/Za0X9ITknZLGk5lU/bvvGODQlIJuA+4DlgM3Cxp\n8cxe1bT5OrC8oWwt8HBE9AMPp/3ZZgL4o4h4G/Bu4Jb033i29/0YcHVEvANYAiyX9G7gbuCe1O+j\nwKoZvMbp9Fng6cx+p/T79yNiSeaR2Cn7d96xQQEsBUYiYl9EHAc2AStm+JqmRUT8b2rrhGStADam\n7Y3ADRf0oi6AiDgUEY+l7Zeo/fKYzyzve9S8nHa701cAVwNbUvms6zeApAXAvwO+lvZFB/S7iSn7\nd97JQTEfOJDZH01lneLyiDgEtV+owGUzfD3TSlIf8E5gBx3Q93T7ZTdwGHgI+Anwi7TEMMzef+9f\nAv4TcDLtz6Uz+h3A30raJWl1Kpuyf+dF1syerZRT5kfAZiFJbwT+CvhcRPyy9kfm7JZWklwi6WLg\nQeBtedUu7FVNL0kfBA5HxC5J76sX51SdVf1O3hsRByVdBjwk6cdT2XgnjyhGgYWZ/QXAwRm6lpnw\nnKR5AOn74Rm+nmkhqZtaSPxlRHwnFXdE3wEi4hfA31Gbo7lYUv2Pw9n47/29wPWS9lO7lXw1tRHG\nbO83EXEwfT9M7Q+DpUzhv/NODoqdQH96IqKH2jrfQzN8TRfSELAyba8EvjuD1zIt0v3p9cDTEfHn\nmUOzuu+SetNIAkmvA/4ttfmZ7cCNqdqs63dE3BYRCyKij9r/z49ExMeY5f2W9AZJb6pvA9cCTzKF\n/847+gN3kj5A7S+OErAhIu6a4UuaFpK+BbyP2tsknwP+K/A/gAeAtwA/A26KiMYJ79c0Sb8H/D3w\nBKfvWf8xtXmKWdt3SW+nNnlZovbH4AMRcaek36D2l/alwOPAxyPi2Mxd6fRJt55ujYgPzvZ+p/49\nmHbLwDcj4i5Jc5mif+cdHRRmZtZeJ996MjOzAhwUZmbWkoPCzMxaclCYmVlLDgozM2vJQWFmZi05\nKMzMrCUHhZmZtfT/Ab6/xVdxKvf+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reintialize weights\n",
    "weights = np.random.normal(size=4)\n",
    "# Perform training\n",
    "weights = train(training_data, training_labels, weights, 50, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print('Weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [ 0.  1.  2.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "pred = output_formula(test_data, weights)\n",
    "print(test_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray: 100.000000%\n"
     ]
    }
   ],
   "source": [
    "ps = pred.sum()\n",
    "ts = test_labels.sum()\n",
    "\n",
    "accuracy = (ts / ps if ps > ts else ps / ts) * 100.0\n",
    "print('Accuray: %f%%' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
